# NVIDIA Privacy Model Service Environment Variables Template

# Model Configuration
# Path where the model will be cached (default: ~/.cache/gliner)
MODEL_PATH=~/.cache/gliner

# Model download URL (default: nvidia/GliNER-PII)
MODEL_DOWNLOAD_URL=nvidia/GliNER-PII

# Default threshold for entity detection (default: 0.5)
THRESHOLD_DEFAULT=0.5

# Maximum batch size for processing (default: 100)
MAX_BATCH_SIZE=100

# Device to use for inference (auto, cuda, cpu) (default: auto)
DEVICE=auto

# Logging Configuration
# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Service Configuration
# Port to run the service on (default: 8000)
PORT=8000